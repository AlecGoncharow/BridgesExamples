Summary: The students will be implementing methods to calculate a Cosine Similarity Matrix of lines within a song. The resulting matrix will represent how similar every line in a song is to every other line in that song.
				To do this, students will be creating Hashtables that represent a vector of each lines Term Frequency Inverse Document Frequency(TF-IDF) values. 
				
Variables: 
			String[][] corpus: This represents the entire body of work, all terms.
			
			String[] document: This represents a line in the song, already split and cleaned up for processing
			
			String term: This represents the current term which is currently being processed.
			
			Hashtable<String, Double> vector: This represents the vector of TF-IDF values used in the calculation of Cosine Similarity.
				The key is a String which is the term whose dimension is being represented by the Double value, which is the TF-IDF value of that term.
				
Sample Solution:
public static int termFrequency(String term, String[] document)
	{
		int tf = 0;

		for (String word : document)
		{
			tf += term.equalsIgnoreCase(word) ? 1 : 0;
		}

		return tf;
	}

	public static boolean hasTerm(String term, String[] document)
	{
		for (String word : document)
		{
			if (term.equalsIgnoreCase(word))
				return true;
		}
		return false;
	}

	public static int documentsContainingTerm(String term, String[][] corpus)
	{
		int n = 0;

		for (String[] document : corpus)
		{
			n += hasTerm(term, document) ? 1 : 0;
		}

		return n;
	}

	public static double inverseDocumentFrequency(String term, String[][] corpus)
	{
		return Math.log(corpus.length / (1 + documentsContainingTerm(term, corpus)));
	}

	public static double termFrequencyInverseDocumentFrequency(String term, String[] document, String[][] corpus)
	{
		return termFrequency(term, document) * inverseDocumentFrequency(term, corpus);
	}

	public static String[] getUniqueTerms(String[][] corpus)
	{
		ArrayList<String> uniqueTerms = new ArrayList<>();

		for (String[] document : corpus)
		{
			for (String term : document)
			{
				if (!uniqueTerms.contains(term))
					uniqueTerms.add(term);
			}
		}

		return uniqueTerms.toArray(new String[0]);
	}

	public static Hashtable<String, Double> vectorize(String[] document, String[][] corpus, String[] uniqueTerms)
	{
		Hashtable<String, Double> vector = new Hashtable<>();

		for (String term : uniqueTerms)
		{
			vector.put(term, termFrequencyInverseDocumentFrequency(term, document, corpus));
		}

		return vector;
	}

	public static double cosine(Hashtable<String, Double> v1,  Hashtable<String, Double> v2)
	{
		return dotProduct(v1, v2)/(norm(v1) * norm(v2));
	}

	public static double dotProduct(Hashtable<String, Double> v1,  Hashtable<String, Double> v2)
	{
		double sum = 0;

		for (String key : v1.keySet())
		{
			sum += v1.get(key) * v2.get(key);
		}

		return sum;
	}

	public static double norm(Hashtable<String, Double> vector)
	{
		return Math.sqrt(dotProduct(vector, vector));
	}
	
	